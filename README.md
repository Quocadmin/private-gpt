# PrivateGPT 

<a href="https://trendshift.io/repositories/2601" target="_blank"><img src="https://trendshift.io/api/badge/repositories/2601" alt="imartinez%2FprivateGPT | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/></a>

[![Tests](https://github.com/zylon-ai/private-gpt/actions/workflows/tests.yml/badge.svg)](https://github.com/zylon-ai/private-gpt/actions/workflows/tests.yml?query=branch%3Amain)
[![Website](https://img.shields.io/website?up_message=check%20it&down_message=down&url=https%3A%2F%2Fdocs.privategpt.dev%2F&label=Documentation)](https://docs.privategpt.dev/)
[![Discord](https://img.shields.io/discord/1164200432894234644?logo=discord&label=PrivateGPT)](https://discord.gg/bK6mRVpErU)
[![X (formerly Twitter) Follow](https://img.shields.io/twitter/follow/ZylonPrivateGPT)](https://twitter.com/ZylonPrivateGPT)

![Gradio UI](/fern/docs/assets/ui.png?raw=true)

PrivateGPT is a production-ready AI project that allows you to ask questions about your documents using the power
of Large Language Models (LLMs), even in scenarios without an Internet connection. 100% private, no data leaves your
execution environment at any point.

>[!TIP]
> If you are looking for an **enterprise-ready, fully private AI workspace**
> check out [Zylon's website](https://zylon.ai)  or [request a demo](https://cal.com/zylon/demo?source=pgpt-readme).
> Crafted by the team behind PrivateGPT, Zylon is a best-in-class AI collaborative
> workspace that can be easily deployed on-premise (data center, bare metal...) or in your private cloud (AWS, GCP, Azure...).

The project provides an API offering all the primitives required to build private, context-aware AI applications.
It follows and extends the [OpenAI API standard](https://openai.com/blog/openai-api),
and supports both normal and streaming responses.

The API is divided into two logical blocks:

**High-level API**, which abstracts all the complexity of a RAG (Retrieval Augmented Generation)
pipeline implementation:
- Ingestion of documents: internally managing document parsing,
splitting, metadata extraction, embedding generation and storage.
- Chat & Completions using context from ingested documents:
abstracting the retrieval of context, the prompt engineering and the response generation.

**Low-level API**, which allows advanced users to implement their own complex pipelines:
- Embeddings generation: based on a piece of text.
- Contextual chunks retrieval: given a query, returns the most relevant chunks of text from the ingested documents.

In addition to this, a working [Gradio UI](https://www.gradio.app/)
client is provided to test the API, together with a set of useful tools such as bulk model
download script, ingestion script, documents folder watch, etc.

## üéûÔ∏è Overview
>[!WARNING]
>  This README is not updated as frequently as the [documentation](https://docs.privategpt.dev/).
>  Please check it out for the latest updates!

### Motivation behind PrivateGPT
Generative AI is a game changer for our society, but adoption in companies of all sizes and data-sensitive
domains like healthcare or legal is limited by a clear concern: **privacy**.
Not being able to ensure that your data is fully under your control when using third-party AI tools
is a risk those industries cannot take.

### Primordial version
The first version of PrivateGPT was launched in May 2023 as a novel approach to address the privacy
concerns by using LLMs in a complete offline way.

That version, which rapidly became a go-to project for privacy-sensitive setups and served as the seed
for thousands of local-focused generative AI projects, was the foundation of what PrivateGPT is becoming nowadays;
thus a simpler and more educational implementation to understand the basic concepts required
to build a fully local -and therefore, private- chatGPT-like tool.

If you want to keep experimenting with it, we have saved it in the
[primordial branch](https://github.com/zylon-ai/private-gpt/tree/primordial) of the project.

> It is strongly recommended to do a clean clone and install of this new version of
PrivateGPT if you come from the previous, primordial version.

### Present and Future of PrivateGPT
PrivateGPT is now evolving towards becoming a gateway to generative AI models and primitives, including
completions, document ingestion, RAG pipelines and other low-level building blocks.
We want to make it easier for any developer to build AI applications and experiences, as well as provide
a suitable extensive architecture for the community to keep contributing.

Stay tuned to our [releases](https://github.com/zylon-ai/private-gpt/releases) to check out all the new features and changes included.

## üìÑ Documentation
Full documentation on installation, dependencies, configuration, running the server, deployment options,
ingesting local documents, API details and UI features can be found here: https://docs.privategpt.dev/

## üß© Architecture
Conceptually, PrivateGPT is an API that wraps a RAG pipeline and exposes its
primitives.
* The API is built using [FastAPI](https://fastapi.tiangolo.com/) and follows
  [OpenAI's API scheme](https://platform.openai.com/docs/api-reference).
* The RAG pipeline is based on [LlamaIndex](https://www.llamaindex.ai/).

The design of PrivateGPT allows to easily extend and adapt both the API and the
RAG implementation. Some key architectural decisions are:
* Dependency Injection, decoupling the different components and layers.
* Usage of LlamaIndex abstractions such as `LLM`, `BaseEmbedding` or `VectorStore`,
  making it immediate to change the actual implementations of those abstractions.
* Simplicity, adding as few layers and new abstractions as possible.
* Ready to use, providing a full implementation of the API and RAG
  pipeline.

Main building blocks:
* APIs are defined in `private_gpt:server:<api>`. Each package contains an
  `<api>_router.py` (FastAPI layer) and an `<api>_service.py` (the
  service implementation). Each *Service* uses LlamaIndex base abstractions instead
  of specific implementations,
  decoupling the actual implementation from its usage.
* Components are placed in
  `private_gpt:components:<component>`. Each *Component* is in charge of providing
  actual implementations to the base abstractions used in the Services - for example
  `LLMComponent` is in charge of providing an actual implementation of an `LLM`
  (for example `LlamaCPP` or `OpenAI`).

## üí° Contributing
Contributions are welcomed! To ensure code quality we have enabled several format and
typing checks, just run `make check` before committing to make sure your code is ok.
Remember to test your code! You'll find a tests folder with helpers, and you can run
tests using `make test` command.

Don't know what to contribute? Here is the public 
[Project Board](https://github.com/users/imartinez/projects/3) with several ideas. 

Head over to Discord 
#contributors channel and ask for write permissions on that GitHub project.

## üí¨ Community
Join the conversation around PrivateGPT on our:
- [Twitter (aka X)](https://twitter.com/PrivateGPT_AI)
- [Discord](https://discord.gg/bK6mRVpErU)

## üìñ Citation
If you use PrivateGPT in a paper, check out the [Citation file](CITATION.cff) for the correct citation.  
You can also use the "Cite this repository" button in this repo to get the citation in different formats.

Here are a couple of examples:

#### BibTeX
```bibtex
@software{Zylon_PrivateGPT_2023,
author = {Zylon by PrivateGPT},
license = {Apache-2.0},
month = may,
title = {{PrivateGPT}},
url = {https://github.com/zylon-ai/private-gpt},
year = {2023}
}
```

#### APA
```
Zylon by PrivateGPT (2023). PrivateGPT [Computer software]. https://github.com/zylon-ai/private-gpt
```

## ü§ó Partners & Supporters
PrivateGPT is actively supported by the teams behind:
* [Qdrant](https://qdrant.tech/), providing the default vector database
* [Fern](https://buildwithfern.com/), providing Documentation and SDKs
* [LlamaIndex](https://www.llamaindex.ai/), providing the base RAG framework and abstractions

This project has been strongly influenced and supported by other amazing projects like 
[LangChain](https://github.com/hwchase17/langchain),
[GPT4All](https://github.com/nomic-ai/gpt4all),
[LlamaCpp](https://github.com/ggerganov/llama.cpp),
[Chroma](https://www.trychroma.com/)
and [SentenceTransformers](https://www.sbert.net/).


1. PrivateGPT l√† g√¨?
PrivateGPT l√† m·ªôt d·ª± √°n m√£ ngu·ªìn m·ªü gi√∫p b·∫°n h·ªèi v√† t∆∞∆°ng t√°c v·ªõi AI v·ªÅ t√†i li·ªáu c√° nh√¢n (file PDF, Word, text, v.v.) m·ªôt c√°ch ri√™ng t∆∞, kh√¥ng c·∫ßn Internet. T·ª©c l√† b·∫°n c√≥ th·ªÉ t·∫£i t√†i li·ªáu v√†o h·ªá th·ªëng, r·ªìi h·ªèi AI c√°c c√¢u h·ªèi li√™n quan, m√† d·ªØ li·ªáu kh√¥ng b·ªã g·ª≠i ra ngo√†i m√°y c·ªßa b·∫°n.

Th√≠ch h·ª£p cho nh·ªØng ai quan t√¢m t·ªõi b·∫£o m·∫≠t v√† quy·ªÅn ri√™ng t∆∞ (v√≠ d·ª•: c√¥ng ty, ng√†nh y t·∫ø, ph√°p l√Ω).

T·∫•t c·∫£ qu√° tr√¨nh x·ª≠ l√Ω ƒë·ªÅu di·ªÖn ra tr√™n m√°y t√≠nh c√° nh√¢n ho·∫∑c server n·ªôi b·ªô.

2. PrivateGPT ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o?
D·ª± √°n n√†y cung c·∫•p m·ªôt API (giao di·ªán l·∫≠p tr√¨nh ·ª©ng d·ª•ng), gi√∫p b·∫°n x√¢y d·ª±ng c√°c ·ª©ng d·ª•ng AI ri√™ng t∆∞ li√™n quan ƒë·∫øn t√†i li·ªáu. API n√†y chia l√†m hai ph·∫ßn ch√≠nh:

a. High-level API (D·ªÖ d√πng)
T·ª± ƒë·ªông x·ª≠ l√Ω t√†i li·ªáu: t·∫£i t√†i li·ªáu l√™n, h·ªá th·ªëng t·ª± ƒë·ªông ph√¢n t√≠ch, chia nh·ªè, t·∫°o metadata, sinh embedding, l∆∞u tr·ªØ, v.v.

Chat v·ªõi AI v·ªÅ t√†i li·ªáu: H·ªèi ƒë√°p, t√≥m t·∫Øt, tr√≠ch xu·∫•t th√¥ng tin d·ª±a tr√™n n·ªôi dung t√†i li·ªáu ƒë√£ n·∫°p.

b. Low-level API (N√¢ng cao)
Cho ph√©p l·∫≠p tr√¨nh vi√™n can thi·ªáp s√¢u v√†o t·ª´ng b∆∞·ªõc nh∆∞: sinh embedding, truy xu·∫•t c√°c ƒëo·∫°n vƒÉn b·∫£n li√™n quan nh·∫•t cho m·ªôt truy v·∫•n.

3. Giao di·ªán & C√¥ng c·ª•
Gradio UI: C√≥ s·∫µn m·ªôt giao di·ªán web ƒë·ªÉ b·∫°n th·ª≠ nghi·ªám h·ªèi ƒë√°p v·ªõi AI v·ªÅ t√†i li·ªáu.

H·ªó tr·ª£ nhi·ªÅu c√¥ng c·ª• kh√°c nh∆∞: script t·∫£i model h√†ng lo·∫°t, script n·∫°p t√†i li·ªáu, theo d√µi th∆∞ m·ª•c t√†i li·ªáu, v.v.

4. T·∫°i sao l·∫°i c√≥ PrivateGPT?
C√°c m√¥ h√¨nh AI l·ªõn (LLM) r·∫•t h·ªØu √≠ch, nh∆∞ng nhi·ªÅu doanh nghi·ªáp/ng√†nh ngh·ªÅ kh√¥ng d√°m d√πng v√¨ lo l·ªô d·ªØ li·ªáu.

PrivateGPT gi√∫p m·ªçi ng∆∞·ªùi t·∫≠n d·ª•ng AI m√† kh√¥ng ph·∫£i chia s·∫ª d·ªØ li·ªáu cho b√™n th·ª© ba.

5. Ki·∫øn tr√∫c b√™n trong
S·ª≠ d·ª•ng FastAPI ƒë·ªÉ x√¢y d·ª±ng API, tu√¢n theo chu·∫©n API c·ªßa OpenAI.

D√πng framework LlamaIndex cho c√°c pipeline RAG (Retrieval Augmented Generation) ‚Äì k·∫øt h·ª£p AI v√† t√¨m ki·∫øm d·ªØ li·ªáu trong t√†i li·ªáu.

C√°c th√†nh ph·∫ßn ch√≠nh nh∆∞ LLM (m√¥ h√¨nh AI), Vector Database, Embedding ƒë·ªÅu c√≥ th·ªÉ thay ƒë·ªïi/d·ªÖ m·ªü r·ªông.

C√≥ s·∫µn code m·∫´u, ki·∫øn tr√∫c r√µ r√†ng, d·ªÖ m·ªü r·ªông v√† ƒë√≥ng g√≥p.

6. T√†i li·ªáu & C·ªông ƒë·ªìng
T√†i li·ªáu chi ti·∫øt: https://docs.privategpt.dev/

C√≥ Discord, Twitter, c√°c nh√≥m c·ªông ƒë·ªìng ƒë·ªÉ trao ƒë·ªïi v√† h·ªó tr·ª£.

7. ƒê√≥ng g√≥p & ph√°t tri·ªÉn
Ch√†o ƒë√≥n m·ªçi ƒë√≥ng g√≥p m√£ ngu·ªìn (PR, √Ω t∆∞·ªüng m·ªõi, s·ª≠a l·ªói...).

C√≥ b·∫£ng d·ª± √°n c√¥ng khai ƒë·ªÉ theo d√µi ti·∫øn ƒë·ªô, t√≠nh nƒÉng.

N√™n ki·ªÉm tra code (make check) v√† test tr∆∞·ªõc khi g·ª≠i PR.

8. ƒê·ªëi t√°c & H·ªó tr·ª£
D√πng Qdrant (vector DB), Fern (t√†i li·ªáu, SDK), LlamaIndex (pipeline AI).

C√≥ c·∫£m h·ª©ng/t√≠ch h·ª£p t·ª´ c√°c d·ª± √°n n·ªïi ti·∫øng nh∆∞ LangChain, GPT4All, Llama.cpp, Chroma, SentenceTransformers.

9. B·∫°n c√≥ th·ªÉ d√πng PrivateGPT cho?
T√¨m ki·∫øm, h·ªèi ƒë√°p tr√™n kho t√†i li·ªáu c√¥ng ty/c√° nh√¢n.

T√≠ch h·ª£p v√†o c√°c ·ª©ng d·ª•ng n·ªôi b·ªô c·∫ßn b·∫£o m·∫≠t th√¥ng tin.

X√¢y d·ª±ng chatbot AI ri√™ng cho doanh nghi·ªáp.

10. T·ªïng k·∫øt ng·∫Øn g·ªçn
PrivateGPT = ChatGPT cho t√†i li·ªáu c√° nh√¢n, ch·∫°y ho√†n to√†n c·ª•c b·ªô, c·ª±c k·ª≥ b·∫£o m·∫≠t, d·ªÖ t√≠ch h·ª£p, d·ªÖ ph√°t tri·ªÉn th√™m.
